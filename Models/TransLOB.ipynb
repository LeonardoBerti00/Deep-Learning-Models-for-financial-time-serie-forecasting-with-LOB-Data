{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **TransLOB** \n",
        "This is the implementation of the model TransLOB proposed in the paper *Transformers for limit order books by james wallbridge*"
      ],
      "metadata": {
        "id": "DWSeo4XItT27"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUo7jxtezAoE",
        "outputId": "153e54a9-9275-4f20-d912-fc5af2b4133f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# load packages\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from google.colab import drive\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from torch.utils import data\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from keras import layers\n",
        "from keras.layers import Conv1D, BatchNormalization\n",
        "import tensorflow as tf\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Data**\n"
      ],
      "metadata": {
        "id": "p2-jdRkKvSTP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "OcSo3GDzz-qa",
        "outputId": "fcdd62a1-fddb-4ea4-f31e-262af38d60c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(203800, 40)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndata_path =  \"/content/drive/MyDrive/Data2/DB2.npy\"\\ndec = np.load(data_path)\\n\\nprint(dec.shape)\\ntrain_size = int(0.70 * dec.shape[0])\\nval_size = int(0.15 * dec.shape[0])\\n\\ndec_train = dec[:train_size]\\ndec_val = dec[train_size:val_size+train_size]\\ndec_test = dec[val_size+train_size:]\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# please change the data_path to your local path and unzip the file\n",
        "\n",
        "dec_data = np.loadtxt('/content/drive/MyDrive/Data/Train_Dst_NoAuction_ZScore_CF_7.txt')\n",
        "dec_train = dec_data[:, :int(dec_data.shape[1] * 0.8)]\n",
        "dec_val = dec_data[:, int(dec_data.shape[1] * 0.8):]\n",
        "\n",
        "dec_test1 = np.loadtxt('/content/drive/MyDrive/Data/Test_Dst_NoAuction_ZScore_CF_7.txt')\n",
        "dec_test2 = np.loadtxt('/content/drive/MyDrive/Data/Test_Dst_NoAuction_ZScore_CF_8.txt')\n",
        "dec_test3 = np.loadtxt('/content/drive/MyDrive/Data/Test_Dst_NoAuction_ZScore_CF_9.txt')\n",
        "dec_test = np.hstack((dec_test1, dec_test2, dec_test3))\n",
        "\n",
        "\n",
        "horizon = 5         #if horizon = 5, than k = 10\n",
        "\n",
        "y_train = dec_train[-horizon, :].flatten()\n",
        "\n",
        "y_val = dec_val[-horizon, :].flatten()\n",
        "y_test = dec_test[-horizon, :].flatten()\n",
        "\n",
        "y_train = y_train[99:] - 1\n",
        "y_val = y_val[99:] - 1\n",
        "y_test = y_test[99:] - 1 \n",
        "\n",
        "dec_train = dec_train[:40, :].T\n",
        "dec_val = dec_val[:40, :].T\n",
        "dec_test = dec_test[:40, :].T\n",
        "\n",
        "print(dec_train.shape)\n",
        "\n",
        "'''\n",
        "data_path =  \"/content/drive/MyDrive/Data2/DB2.npy\"\n",
        "dec = np.load(data_path)\n",
        "\n",
        "print(dec.shape)\n",
        "train_size = int(0.70 * dec.shape[0])\n",
        "val_size = int(0.15 * dec.shape[0])\n",
        "\n",
        "dec_train = dec[:train_size]\n",
        "dec_val = dec[train_size:val_size+train_size]\n",
        "dec_test = dec[val_size+train_size:]\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "c-q1pXGi0ACD"
      },
      "outputs": [],
      "source": [
        "def labeling(X, T):\n",
        "\n",
        "  [N, D] = X.shape\n",
        "  print(N)\n",
        "  Y = np.zeros((X.shape[0] - 2*T + 1))\n",
        "  alpha = 0.00072\n",
        "  media = []\n",
        "  for i in range(0, X.shape[0]- 2*T + 1):\n",
        "    ask_minus = X[i:i+T, :1]\n",
        "    bid_minus = X[i:i+T, 2:3]\n",
        "    ask_plus = X[i+T:i+2*T, :1]\n",
        "    bid_plus = X[i+T:i+2*T, 2:3]\n",
        "    m_minus = (ask_minus + bid_minus) / 2\n",
        "    m_minus = np.sum(m_minus) / T\n",
        "    m_plus = (ask_plus + bid_plus) / 2\n",
        "    m_plus = np.sum(m_plus) / T\n",
        "    media.append((m_plus - m_minus) / m_minus)\n",
        "    if (m_plus - m_minus) / m_minus < -alpha:\n",
        "      label = 1\n",
        "    elif (m_plus - m_minus) / m_minus > alpha:\n",
        "      label = 0\n",
        "    else:\n",
        "      label = 2\n",
        "    Y[i] = label\n",
        "  \n",
        "  plt.hist(Y)\n",
        "  plt.show()\n",
        "\n",
        "  return Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8x7PAu1LySOZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f9bad48-cffd-443e-acec-08b13b41dfa8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50751\n",
            "139388\n",
            "203601\n"
          ]
        }
      ],
      "source": [
        "#Create the dataset\n",
        "\n",
        "class Dataset(data.Dataset):\n",
        "    \"\"\"Characterizes a dataset for PyTorch\"\"\"\n",
        "    def __init__(self, x, y, num_classes, n, dim):\n",
        "        \"\"\"Initialization\"\"\" \n",
        "        self.num_classes = num_classes\n",
        "        self.dim = dim\n",
        "        self.x = x   \n",
        "        self.y = y\n",
        "        self.n = n\n",
        "\n",
        "        self.length = x.shape[0] - T -self.dim + 1\n",
        "        print(self.length)\n",
        "\n",
        "        x = torch.from_numpy(x)\n",
        "        self.x = torch.unsqueeze(x, 1)\n",
        "        self.y = torch.from_numpy(y)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Denotes the total number of samples\"\"\"\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        input = self.x[i:i+self.dim, :]\n",
        "        input = input.permute(1, 0, 2)\n",
        "        input = np.squeeze(input)\n",
        "        input = input.permute(1, 0)\n",
        "        return input, self.y[i]\n",
        "\n",
        "#Hyperparameters\n",
        "batch_size = 32\n",
        "epochs = 100\n",
        "T = 100   #horizon    \n",
        "lr = 0.0001\n",
        "num_classes = 3\n",
        "dim = 100\n",
        "n = 3 \n",
        "\n",
        "#y_val = labeling(dec_val, T, dim)\n",
        "#y_test = labeling(dec_test, T, dim)\n",
        "#y_train = labeling(dec_train, T, dim)\n",
        "\n",
        "dataset_val = Dataset(dec_val, y_val, num_classes, n, dim)\n",
        "dataset_test = Dataset(dec_test, y_test, num_classes, n, dim)\n",
        "dataset_train = Dataset(dec_train, y_train, num_classes, n, dim)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=dataset_train, batch_size=batch_size, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(dataset=dataset_val, batch_size=batch_size, shuffle=False)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=dataset_test, batch_size=batch_size, shuffle=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model Architecture**\n",
        "The model architecture is specified in the original paper."
      ],
      "metadata": {
        "id": "_0wAgGUv8Yhi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "mBLoNDNIAAs9"
      },
      "outputs": [],
      "source": [
        "from keras import layers\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, Reshape\n",
        "from keras.layers import Dropout, Activation, Lambda\n",
        "from keras.layers import LSTM, Conv1D, Conv2D, Flatten\n",
        "from keras.layers import MaxPooling1D, MaxPooling2D, Reshape, BatchNormalization\n",
        "import tensorflow as tf\n",
        "import keras.backend as K\n",
        "\n",
        "\n",
        "def positional_encoding(x):\n",
        "  n_levels = 100\n",
        "  pos = np.arange(0, n_levels,  1, dtype=np.float32) / (n_levels-1)\n",
        "  pos = (pos + pos) - 1\n",
        "  #pos = np.reshape(pos, (pos.shape[0]))\n",
        "  pos_final = np.zeros((x.shape[0], n_levels, 1), dtype=np.float32)\n",
        "  for i in range(pos_final.shape[0]):\n",
        "    for j in range(pos_final.shape[1]):\n",
        "      pos_final[i, j, 0] = pos[j]\n",
        "\n",
        "  pos_final = torch.tensor(pos_final).to(device)\n",
        "  x = torch.cat((x, pos_final), 2)\n",
        "  \n",
        "  return x\n",
        "\n",
        "class transformer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        #self.transformer = nn.Transformer(d_model=15, nhead=3, \n",
        "                                            #num_encoder_layers=2, num_decoder_layers=2, \n",
        "                                            #dim_feedforward=3000, dropout=0.0, norm_first=True,\n",
        "                                            #batch_first=True, device=device)\n",
        "        \n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv1d(in_channels=40, out_channels=14, kernel_size=2, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(in_channels=14, out_channels=14, kernel_size=2, dilation=2, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(in_channels=14, out_channels=14, kernel_size=2, dilation=4, padding=4),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(in_channels=14, out_channels=14, kernel_size=2, dilation=8, padding=8),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(in_channels=14, out_channels=14, kernel_size=2, dilation=16, padding=16),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(14),\n",
        "        )\n",
        "\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "        self.activation = nn.ReLU()\n",
        "\n",
        "        self.encoder_layer = nn.TransformerEncoderLayer(15, 3, 60, 0.0, batch_first=True, device=device)\n",
        "        self.norm = nn.BatchNorm1d(100)\n",
        " \n",
        "        self.transformer = nn.TransformerEncoder(self.encoder_layer, 2, norm=self.norm)\n",
        "        \n",
        "        self.fc1 = nn.Linear(1500, 64)\n",
        "        self.fc2 = nn.Linear(64, 3)\n",
        "     \n",
        "    def forward(self, x):\n",
        "        '''\n",
        "        np_tensor = x.cpu().numpy()\n",
        "        tf_tensor = tf.convert_to_tensor(np_tensor)\n",
        "\n",
        "        x = lob_dilated(tf_tensor)          \n",
        "        '''\n",
        "        \n",
        "        x = self.conv(x)\n",
        "        x = x[:, :, :-31]\n",
        "        x = x.permute(0, 2, 1)\n",
        "        #np_tensor = x.cpu().detach().numpy()\n",
        "        #tf_tensor = tf.convert_to_tensor(np_tensor)\n",
        "        \n",
        "        x = positional_encoding(x)\n",
        "        \n",
        "\n",
        "        #np_tensor = x.cpu().numpy()\n",
        "        #np_tensor = np.squeeze(np_tensor)\n",
        "   \n",
        "       #x = torch.tensor(np_tensor).to(device)\n",
        "\n",
        "        x = self.transformer(x)\n",
        "        #print(x.shape)\n",
        "        x = torch.reshape(x, (x.shape[0], x.shape[1]*x.shape[2]))\n",
        "\n",
        "        x = self.dropout(self.activation(self.fc1(x)))\n",
        "        #x = self.dropout(self.norm2(self.activation(self.fc2(x))))\n",
        "        x = self.fc2(x)\n",
        "        forecast_y = torch.softmax(x, dim=1)\n",
        "        \n",
        "        return forecast_y"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model Training**"
      ],
      "metadata": {
        "id": "8CaGko8X8lmC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "s_u5esKfTT-S"
      },
      "outputs": [],
      "source": [
        "model = transformer()\n",
        "model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr, weight_decay=1e-5)\n",
        "\n",
        "def batch_gd(model, criterion, optimizer, train_loader, test_loader, epochs):\n",
        "    \n",
        "    train_losses = np.zeros(epochs)\n",
        "    test_losses = np.zeros(epochs)\n",
        "    best_test_loss = np.inf\n",
        "    best_test_epoch = 0\n",
        "\n",
        "    for it in tqdm(range(epochs)):\n",
        "        \n",
        "        model.train()\n",
        "        t0 = datetime.now()\n",
        "        train_loss = []\n",
        "        for inputs, targets in train_loader:\n",
        "            # move data to GPU\n",
        "            inputs, targets = inputs.to(device, dtype=torch.float), targets.to(device, dtype=torch.int64)\n",
        "            # print(\"inputs.shape:\", inputs.shape)\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "            # Forward pass\n",
        "            # print(\"about to get model output\")\n",
        "            outputs = model(inputs)\n",
        "            # print(\"done getting model output\")\n",
        "            # print(\"outputs.shape:\", outputs.shape, \"targets.shape:\", targets.shape)\n",
        "            loss = criterion(outputs, targets)\n",
        "            # Backward and optimize\n",
        "            # print(\"about to optimize\")\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss.append(loss.item())\n",
        "        # Get train loss and test loss\n",
        "        train_loss = np.mean(train_loss) # a little misleading\n",
        "    \n",
        "        model.eval()\n",
        "        test_loss = []\n",
        "        for inputs, targets in test_loader:\n",
        "            inputs, targets = inputs.to(device, dtype=torch.float), targets.to(device, dtype=torch.int64)      \n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            test_loss.append(loss.item())\n",
        "        test_loss = np.mean(test_loss)\n",
        "\n",
        "        # Save losses\n",
        "        train_losses[it] = train_loss\n",
        "        test_losses[it] = test_loss\n",
        "        \n",
        "        if test_loss < best_test_loss:\n",
        "            torch.save(model, '/content/drive/MyDrive/Output/best_model_transformer')\n",
        "            best_test_loss = test_loss\n",
        "            best_test_epoch = it\n",
        "            print('model saved')\n",
        "\n",
        "        dt = datetime.now() - t0\n",
        "        print(f'Epoch {it+1}/{epochs}, Train Loss: {train_loss:.4f}, \\\n",
        "          Validation Loss: {test_loss:.4f}, Duration: {dt}, Best Val Epoch: {best_test_epoch}')\n",
        "\n",
        "    return train_losses, test_losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "EwRTC160vqW5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        },
        "outputId": "cfb7c29c-cac4-4311-c2b0-f8fd12407728"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 1/100 [01:31<2:31:18, 91.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model saved\n",
            "Epoch 1/100, Train Loss: 0.9450,           Validation Loss: 0.9178, Duration: 0:01:31.703095, Best Val Epoch: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 2/100 [02:59<2:26:21, 89.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model saved\n",
            "Epoch 2/100, Train Loss: 0.9442,           Validation Loss: 0.9178, Duration: 0:01:28.134393, Best Val Epoch: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 3/100 [04:28<2:24:18, 89.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model saved\n",
            "Epoch 3/100, Train Loss: 0.9437,           Validation Loss: 0.9178, Duration: 0:01:28.856953, Best Val Epoch: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 4/100 [05:56<2:21:40, 88.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/100, Train Loss: 0.9432,           Validation Loss: 0.9178, Duration: 0:01:27.445117, Best Val Epoch: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 5/100 [07:24<2:20:14, 88.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model saved\n",
            "Epoch 5/100, Train Loss: 0.9425,           Validation Loss: 0.9178, Duration: 0:01:28.612821, Best Val Epoch: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 6/100 [08:52<2:18:06, 88.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/100, Train Loss: 0.9416,           Validation Loss: 0.9178, Duration: 0:01:27.342683, Best Val Epoch: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 7/100 [10:18<2:15:57, 87.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/100, Train Loss: 0.9407,           Validation Loss: 0.9178, Duration: 0:01:26.790978, Best Val Epoch: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 7/100 [10:43<2:22:30, 91.94s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-c2c99f33d05b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train_losses, val_losses = batch_gd(model, criterion, optimizer, \n\u001b[0m\u001b[1;32m      2\u001b[0m                                     train_loader, val_loader, epochs)\n",
            "\u001b[0;32m<ipython-input-10-e370feb44f9a>\u001b[0m in \u001b[0;36mbatch_gd\u001b[0;34m(model, criterion, optimizer, train_loader, test_loader, epochs)\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;31m# Backward and optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;31m# print(\"about to optimize\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "train_losses, val_losses = batch_gd(model, criterion, optimizer, \n",
        "                                    train_loader, val_loader, epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model Testing**"
      ],
      "metadata": {
        "id": "ja-2FWDj8pt6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "TFg5d6CzTgWS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "4c8d280a-8140-4b20-a6fc-1ee247030b13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test acc: 0.7059\n",
            "accuracy_score: 0.7059431227939278\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.2449    0.0006    0.0011     21127\n",
            "           1     0.7067    0.9986    0.8277     98502\n",
            "           2     0.1439    0.0010    0.0020     19759\n",
            "\n",
            "    accuracy                         0.7059    139388\n",
            "   macro avg     0.3651    0.3334    0.2769    139388\n",
            "weighted avg     0.5569    0.7059    0.5853    139388\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-8a6e3c677951>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'accuracy_score:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_targets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_predictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_targets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdigits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_targets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_prediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'all_prediction' is not defined"
          ]
        }
      ],
      "source": [
        "model = torch.load('/content/drive/MyDrive/Output/best_model_transformer')\n",
        "\n",
        "n_correct = 0.\n",
        "n_total = 0.\n",
        "all_targets = []\n",
        "all_predictions = []\n",
        "\n",
        "for inputs, targets in test_loader:\n",
        "    # Move to GPU\n",
        "    inputs, targets = inputs.to(device, dtype=torch.float), targets.to(device, dtype=torch.int64)\n",
        "\n",
        "    # Forward pass\n",
        "    outputs = model(inputs)\n",
        "    \n",
        "    # Get prediction\n",
        "    # torch.max returns both max and argmax\n",
        "    _, predictions = torch.max(outputs, 1)\n",
        "\n",
        "    # update counts\n",
        "    n_correct += (predictions == targets).sum().item()\n",
        "    n_total += targets.shape[0]\n",
        "\n",
        "    all_targets.append(targets.cpu().numpy())\n",
        "    all_predictions.append(predictions.cpu().numpy())\n",
        "\n",
        "test_acc = n_correct / n_total\n",
        "print(f\"Test acc: {test_acc:.4f}\")\n",
        "\n",
        "all_targets = np.concatenate(all_targets)    \n",
        "all_predictions = np.concatenate(all_predictions)   \n",
        "\n",
        "print('accuracy_score:', accuracy_score(all_targets, all_predictions))\n",
        "print(classification_report(all_targets, all_predictions, digits=4))\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "c = confusion_matrix(all_targets, all_predictions, normalize=\"true\")\n",
        "disp = ConfusionMatrixDisplay(c)\n",
        "disp.plot()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
