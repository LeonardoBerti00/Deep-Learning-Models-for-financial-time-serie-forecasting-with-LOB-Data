{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8ywNFBrj5wl"
      },
      "source": [
        "### **Deep Convolutional Neural Network**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVJUk8Tw-nRH",
        "outputId": "8b283134-0a6c-4f39-e44d-3475fca17bba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# load packages\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm \n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import torch\n",
        "from torch.utils import data\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owDFOiYck5-Y"
      },
      "source": [
        "### **Data**\n",
        "The dataset in the folder Dataset is the LOBSTER dataset zipped and normalized. I have combined the data of the 5 stocks available for free. I used the version with 10 levels, so we have 40 columns, in fact for every level we have a quadruple wiht the ask and bid prices and with the volumes associated, for more information i reference to the thesis. \n",
        "\n",
        "I used 70% to do the training, 15% to do the validation and 15% for the testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBPfIw0eicai",
        "outputId": "b881aee7-dc9f-4b0d-9f2a-5e59f6727c40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(922925, 40)\n"
          ]
        }
      ],
      "source": [
        "# please change the data_path to your local path and unzip the file\n",
        "\n",
        "data_path =  \"/data.npy"\n",
        "\n",
        "dec = np.load(data_path)\n",
        "\n",
        "train_size = int(0.70 * dec.shape[0])\n",
        "val_size = int(0.15 * dec.shape[0])\n",
        "\n",
        "print(dec.shape)\n",
        "dec_train = dec[:train_size]\n",
        "dec_val = dec[train_size:val_size+train_size]\n",
        "dec_test = dec[val_size+train_size:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "loWTynZ6-0nC"
      },
      "outputs": [],
      "source": [
        "#Label the data with the method explained in the thesis\n",
        "\n",
        "def labeling(X, T):\n",
        "\n",
        "  [N, D] = X.shape\n",
        "  print(N)\n",
        "  Y = np.zeros((X.shape[0] - 2*T + 1))\n",
        "  alpha = 0.00072\n",
        "  media = []\n",
        "  for i in range(0, X.shape[0]- 2*T + 1):\n",
        "    ask_minus = X[i:i+T, :1]\n",
        "    bid_minus = X[i:i+T, 2:3]\n",
        "    ask_plus = X[i+T:i+2*T, :1]\n",
        "    bid_plus = X[i+T:i+2*T, 2:3]\n",
        "    m_minus = (ask_minus + bid_minus) / 2\n",
        "    m_minus = np.sum(m_minus) / T\n",
        "    m_plus = (ask_plus + bid_plus) / 2\n",
        "    m_plus = np.sum(m_plus) / T\n",
        "    media.append((m_plus - m_minus) / m_minus)\n",
        "    if (m_plus - m_minus) / m_minus < -alpha:\n",
        "      label = 1\n",
        "    elif (m_plus - m_minus) / m_minus > alpha:\n",
        "      label = 0\n",
        "    else:\n",
        "      label = 2\n",
        "    Y[i] = label\n",
        "  \n",
        "  plt.hist(Y)\n",
        "  plt.show()\n",
        "\n",
        "  return Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8x7PAu1LySOZ"
      },
      "outputs": [],
      "source": [
        "class Dataset(data.Dataset):\n",
        "    \"\"\"Characterizes a dataset for PyTorch\"\"\"\n",
        "    def __init__(self, x, y, num_classes, T):\n",
        "        \"\"\"Initialization\"\"\" \n",
        "        self.num_classes = num_classes\n",
        "        self.T = T\n",
        "        self.x = x   \n",
        "        self.y = y\n",
        "         \n",
        "        self.length = x.shape[0] - 2*T + 1\n",
        "\n",
        "        x = torch.from_numpy(x)\n",
        "        self.x = torch.unsqueeze(x, 1)\n",
        "        self.y = torch.from_numpy(y)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Denotes the total number of samples\"\"\"\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        input = self.x[i:i+self.T, :]\n",
        "        input = input.permute(1, 0, 2)\n",
        "      \n",
        "        return input, self.y[i]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 872
        },
        "id": "S5r5u-0fP_nM",
        "outputId": "7420ce8c-465f-4999-c2fb-8d0cee3d4fce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "138438\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "138440\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "646047\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "138339\n",
            "138341\n",
            "645948\n"
          ]
        }
      ],
      "source": [
        "#Hyperparameters\n",
        "batch_size = 64\n",
        "epochs = 50\n",
        "T = 50     \n",
        "lr = 0.00008\n",
        "\n",
        "y_val = labeling(dec_val, T)\n",
        "y_test = labeling(dec_test, T)\n",
        "y_train = labeling(dec_train, T)\n",
        "\n",
        "dataset_val = Dataset(dec_val, y_val, num_classes=3, T=50)\n",
        "dataset_test = Dataset(dec_test, y_test, num_classes=3, T=50)\n",
        "dataset_train = Dataset(dec_train, y_train, num_classes=3, T=50)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=dataset_train, batch_size=batch_size, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(dataset=dataset_val, batch_size=batch_size, shuffle=False)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=dataset_test, batch_size=batch_size, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0xCPcR6neps"
      },
      "source": [
        "### **Model Architecture**\n",
        "the structure is made up of 15 convolutional layer and 3 fully connected layer. The activation function used is LeakyReLU. As for the hyperparameters, a learning rate equal to 0.00008, 50 epochs and a batch size of 64 was used. The model in total has 168,132,646 parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_CEOaOyW_Fm2"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, y_len):\n",
        "        super().__init__()\n",
        "        self.y_len = y_len\n",
        "        \n",
        "        # convolution blocks\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(1,2), stride=(1,2)),\n",
        "            nn.LeakyReLU(negative_slope=0.01),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
        "            nn.LeakyReLU(negative_slope=0.01),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
        "            nn.LeakyReLU(negative_slope=0.01),\n",
        "            nn.BatchNorm2d(32),\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(1,2), stride=(1,2)),\n",
        "            nn.LeakyReLU(negative_slope=0.01),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
        "            nn.LeakyReLU(negative_slope=0.01),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
        "            nn.LeakyReLU(negative_slope=0.01),\n",
        "            nn.BatchNorm2d(32),\n",
        "        )\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(1,10)),\n",
        "            nn.LeakyReLU(negative_slope=0.01),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
        "            nn.LeakyReLU(negative_slope=0.01),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
        "            nn.LeakyReLU(negative_slope=0.01),\n",
        "            nn.BatchNorm2d(32),\n",
        "        )\n",
        "        self.inp1 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, (3,1), padding=\"same\"),\n",
        "            nn.LeakyReLU(negative_slope=0.01),\n",
        "            nn.Conv2d(64, 64, (1,1), padding=\"same\"),\n",
        "            nn.LeakyReLU(negative_slope=0.01),\n",
        "            #nn.MaxPool2d(2, 2),\n",
        "\n",
        "            nn.Conv2d(64, 128, (3,1), padding=\"same\"),\n",
        "            nn.LeakyReLU(negative_slope=0.01),\n",
        "            nn.Conv2d(128, 128, (1,1), padding=\"same\"),\n",
        "            nn.LeakyReLU(negative_slope=0.01),\n",
        "\n",
        "            nn.Conv2d(128, 256, (3,1), padding=\"same\"),\n",
        "            nn.LeakyReLU(negative_slope=0.01),\n",
        "            nn.Conv2d(256, 256, (1,1), padding=\"same\"),\n",
        "            nn.LeakyReLU(negative_slope=0.01),\n",
        "            nn.Conv2d(256, 256, 1),\n",
        "            nn.LeakyReLU(negative_slope=0.01),\n",
        "            \n",
        "        )\n",
        "        \n",
        "        #fully connected layers\n",
        "        self.linear1 = nn.Linear(8192, 4096)\n",
        "        self.linear2 = nn.Linear(4096, 4096)\n",
        "        self.linear3 = nn.Linear(4096, 3)\n",
        "\n",
        "        #activation\n",
        "        self.activation = nn.LeakyReLU(negative_slope=0.01)\n",
        "      \n",
        "    def forward(self, x):\n",
        "      #print(x.shape)\n",
        "      x = self.conv1(x)\n",
        "      #print(x.shape)\n",
        "      x = self.conv2(x)\n",
        "      #print(x.shape)\n",
        "      x = self.conv3(x)\n",
        "      #print(x.shape)\n",
        "      x = self.inp1(x)\n",
        "       \n",
        "      x = torch.flatten(x, 1)\n",
        "      x = self.activation(self.linear1(x))\n",
        "      #print(x.shape)\n",
        "      x = self.activation(self.linear2(x))\n",
        "      #print(x.shape)\n",
        "      out = self.linear3(x)\n",
        "      forecast_y = torch.softmax(out, dim=1)\n",
        "      \n",
        "      return forecast_y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPaZwcu1oPtc"
      },
      "source": [
        "### **Model Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s_u5esKfTT-S"
      },
      "outputs": [],
      "source": [
        "model = CNN(3)\n",
        "model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr)\n",
        "\n",
        "def batch_gd(model, criterion, optimizer, train_loader, test_loader, epochs):\n",
        "    \n",
        "    train_losses = np.zeros(epochs)\n",
        "    test_losses = np.zeros(epochs)\n",
        "    best_test_loss = np.inf\n",
        "    best_test_epoch = 0\n",
        "\n",
        "    for it in tqdm(range(epochs)):\n",
        "        \n",
        "        model.train()\n",
        "        t0 = datetime.now()\n",
        "        train_loss = []\n",
        "        for inputs, targets in train_loader:\n",
        "            # move data to GPU\n",
        "            inputs, targets = inputs.to(device, dtype=torch.float), targets.to(device, dtype=torch.int64)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            # Backward and optimize\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss.append(loss.item())\n",
        "\n",
        "        # Get train loss and test loss\n",
        "        train_loss = np.mean(train_loss) \n",
        "    \n",
        "        model.eval()\n",
        "        test_loss = []\n",
        "        n_correct = 0.\n",
        "        n_total = 0.\n",
        "        for inputs, targets in test_loader:\n",
        "            inputs, targets = inputs.to(device, dtype=torch.float), targets.to(device, dtype=torch.int64)      \n",
        "            outputs = model(inputs)\n",
        "            _, predictions = torch.max(outputs, 1)\n",
        "            loss = criterion(outputs, targets)\n",
        "            test_loss.append(loss.item())\n",
        "            n_correct += (predictions == targets).sum().item()\n",
        "            n_total += targets.shape[0]\n",
        "\n",
        "        test_acc = n_correct / n_total\n",
        "        print(f\"Test acc: {test_acc:.4f}\")\n",
        "        test_loss = np.mean(test_loss)\n",
        "\n",
        "        # Save losses\n",
        "        train_losses[it] = train_loss\n",
        "        test_losses[it] = test_loss\n",
        "        \n",
        "        #We save the best model\n",
        "        if test_loss < best_test_loss:\n",
        "            torch.save(model, '/best_model_CNN')\n",
        "            best_test_loss = test_loss\n",
        "            best_test_epoch = it\n",
        "            print('model saved')\n",
        "\n",
        "        dt = datetime.now() - t0\n",
        "        print(f'Epoch {it+1}/{epochs}, Train Loss: {train_loss:.4f}, \\\n",
        "          Validation Loss: {test_loss:.4f}, Duration: {dt}, Best Val Epoch: {best_test_epoch}')\n",
        "    
        "    return train_losses, test_losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "x9vq-ZAzTb6K"
      },
      "outputs": [],
      "source": [
        "print(\"------- List Hyper Parameters -------\")\n",
        "print(\"epochs   ->   \" + str(epochs))\n",
        "print(\"learningRate   ->   \" + str(lr))\n",
        "print(\"training range   ->   \" + str(train_size))\n",
        "print(\"horizon    ->     \" + str(T))\n",
        "print(\"Optimizer   ->    AdamW\")\n",
        "\n",
        "train_losses, val_losses = batch_gd(model, criterion, optimizer, train_loader, val_loader, epochs)\n",
        "\n",
        "plt.figure(figsize=(15,6))\n",
        "plt.plot(train_losses, label='train loss')\n",
        "plt.plot(val_losses, label='validation loss')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpbF0l-rJWC3"
      },
      "source": [
        "### **Model Testing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TFg5d6CzTgWS"
      },
      "outputs": [],
      "source": [
        "model = torch.load('/best_model_CNN')\n",
        "\n",
        "n_correct = 0.\n",
        "n_total = 0.\n",
        "all_targets = []\n",
        "all_predictions = []\n",
        "\n",
        "for inputs, targets in test_loader:\n",
        "    # Move to GPU\n",
        "    inputs, targets = inputs.to(device, dtype=torch.float), targets.to(device, dtype=torch.int64)\n",
        "\n",
        "    # Forward pass\n",
        "    outputs = model(inputs)\n",
        "    \n",
        "    # Get prediction\n",
        "    # torch.max returns both max and argmax\n",
        "    _, predictions = torch.max(outputs, 1)\n",
        "\n",
        "    # update counts\n",
        "    n_correct += (predictions == targets).sum().item()\n",
        "    n_total += targets.shape[0]\n",
        "\n",
        "    all_targets.append(targets.cpu().numpy())\n",
        "    all_predictions.append(predictions.cpu().numpy())\n",
        "\n",
        "test_acc = n_correct / n_total\n",
        "print(f\"Test acc: {test_acc:.4f}\")\n",
        "  \n",
        "all_targets = np.concatenate(all_targets)    \n",
        "all_predictions = np.concatenate(all_predictions)    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0oOu5lwf6zw0"
      },
      "outputs": [],
      "source": [
        "print('accuracy_score:', accuracy_score(all_targets, all_predictions))\n",
        "print(classification_report(all_targets, all_predictions, digits=4))\n",
        "print(confusion_matrix(all_targets, all_prediction, normalize=True))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
