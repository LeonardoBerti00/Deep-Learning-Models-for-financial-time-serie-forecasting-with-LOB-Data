{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **DCNN-LSTM LOB**"
      ],
      "metadata": {
        "id": "P-PVsZeWjCiw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Initially we download the zipped data\n",
        "\n",
        "import os \n",
        "if not os.path.isfile('data.zip'):\n",
        "    !wget https://github.com/LeonardoBerti07/Deep-Learning-Algorithms-for-financial-time-serie-modeling-/blob/main/Datasets/DB2.zip\n",
        "    !unzip -n data.zip\n",
        "    print('data downloaded.')\n",
        "else:\n",
        "    print('data already existed.')"
      ],
      "metadata": {
        "id": "Tr8jwTVRjAsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVPONVeVw0nh",
        "outputId": "e2009b75-7fa9-48b0-bdde-b82a91d9f0cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# load packages\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm \n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils import data\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n" 
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Data**\n",
        "The dataset in the folder Dataset is the LOBSTER dataset zipped and normalized. I have combined the data of the 5 stocks available for free. I used the version with 10 levels, so we have 40 columns, in fact for every level we have a quadruple wiht the ask and bid prices and with the volumes associated, for more information i reference to the thesis.\n",
        "\n",
        "I used 70% to do the training, 15% to do the validation and 15% for the testing."
      ],
      "metadata": {
        "id": "aNdy1u5zjMaw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ls5u0jngxkjl"
      },
      "outputs": [],
      "source": [
        "#please change the data_path to your local path\n",
        "\n",
        "data_path = \"/DB2.npy\"\n",
        "\n",
        "dec = np.load(data_path)\n",
        "\n",
        "train_size = int(0.70 * dec.shape[0])\n",
        "val_size = int(0.15 * dec.shape[0])\n",
        "\n",
        "dec_train = dec[:train_size]\n",
        "dec_val = dec[train_size:val_size+train_size]\n",
        "dec_test = dec[val_size+train_size:]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "KspbKX4q8TRM"
      },
      "outputs": [],
      "source": [
        "#Label the data with the method explained in the thesis\n",
        "\n",
        "def labeling(X, T):\n",
        "\n",
        "  [N, D] = X.shape\n",
        "  print(N)\n",
        "  x = np.zeros((N - T + 1, T, D))\n",
        "  for i in range(T, N + 1-T):\n",
        "      x[i - T] = X[i - T:i, :]\n",
        "\n",
        "  Y = np.zeros((x.shape[0] - T, 1))\n",
        "  alpha = 0.00072\n",
        "  media = []\n",
        "  for i in range(0, x.shape[0]-T):\n",
        "    ask_minus = x[i, :, :1]\n",
        "    bid_minus = x[i, :, 2:3]\n",
        "    ask_plus = x[i+T, :, :1]\n",
        "    bid_plus = x[i+T, :, 2:3]\n",
        "    m_minus = (ask_minus + bid_minus) / 2\n",
        "    m_minus = np.sum(m_minus) / T\n",
        "    m_plus = (ask_plus + bid_plus) / 2\n",
        "    m_plus = np.sum(m_plus) / T\n",
        "    media.append((m_plus - m_minus) / m_minus)\n",
        "    if (m_plus - m_minus) / m_minus < -alpha:\n",
        "      label = 1\n",
        "    elif (m_plus - m_minus) / m_minus > alpha:\n",
        "      label = 0\n",
        "    else:\n",
        "      label = 2\n",
        "    Y[i, 0] = label\n",
        "  \n",
        "  plt.hist(Y)\n",
        "  plt.show()\n",
        "  x = x[:x.shape[0]-T, :, :]\n",
        "  Y = np.reshape(Y, (Y.shape[0]))\n",
        "  return x, Y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 870
        },
        "id": "8x7PAu1LySOZ",
        "outputId": "9c6e3d1e-850d-4700-f03e-cc9e0f5202d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1477602\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1477503, 50, 40)\n",
            "316629\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(316530, 50, 40)\n",
            "316629\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(316530, 50, 40)\n"
          ]
        }
      ],
      "source": [
        "class Dataset(data.Dataset):\n",
        "    \"\"\"Characterizes a dataset for PyTorch\"\"\"\n",
        "    def __init__(self, data, num_classes, T):\n",
        "        \"\"\"Initialization\"\"\" \n",
        "        self.num_classes = num_classes\n",
        "        self.T = T\n",
        "            \n",
        "        x, y = labeling(data, self.T)\n",
        "        print(x.shape)\n",
        "        self.length = len(x)\n",
        "\n",
        "        x = torch.from_numpy(x)\n",
        "        self.x = torch.unsqueeze(x, 1)\n",
        "        self.y = torch.from_numpy(y)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Denotes the total number of samples\"\"\"\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"Generates samples of data\"\"\"\n",
        "        return self.x[index], self.y[index]\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Hyperparameters\n",
        "\n",
        "batch_size = 64\n",
        "epochs = 50\n",
        "T = 50     \n",
        "lr=0.0001\n",
        "\n",
        "dataset_train = Dataset(data=dec_train, num_classes=3, T=50)\n",
        "dataset_val = Dataset(data=dec_val, num_classes=3, T=50)\n",
        "dataset_test = Dataset(data=dec_test, num_classes=3, T=50)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=dataset_train, batch_size=batch_size, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(dataset=dataset_val, batch_size=batch_size, shuffle=False)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=dataset_test, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "7ndByE-Ajmq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model Architecture**\n",
        "The Architecture of the DCNN is composed of 9 convolutional layers, subsequently there is an inception module composed of 5 parts, each part is made up of 2 convolutional layers, which however are not applied sequentially but each receives in input, the output of the last of the 9 convolutional layers and subsequently all the outputs of each part of the inception module are concatenated and passed in input to the LSTM layer, which has a hidden size of 64. The activation function used is LeakyReLU. The model in total has 1,717,475 parameters."
      ],
      "metadata": {
        "id": "DEIIi2NwjtgC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "SvYo0So0TRoR"
      },
      "outputs": [],
      "source": [
        "class deeplob(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "      \n",
        "        \n",
        "        # convolution blocks\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(1,2), stride=(1,2)),\n",
        "            nn.LeakyReLU(negative_slope=0.01),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
        "            nn.LeakyReLU(negative_slope=0.01),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
        "            nn.LeakyReLU(negative_slope=0.01),\n",
        "            nn.BatchNorm2d(32),\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(1,2), stride=(1,2)),\n",
        "            nn.Tanh(),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
        "            nn.Tanh(),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
        "            nn.Tanh(),\n",
        "            nn.BatchNorm2d(32),\n",
        "        )\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(1,10)),\n",
        "            nn.LeakyReLU(negative_slope=0.01),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
        "            nn.LeakyReLU(negative_slope=0.01),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(4,1)),\n",
        "            nn.LeakyReLU(negative_slope=0.01),\n",
        "            nn.BatchNorm2d(32),\n",
        "        )\n",
        "        \n",
        "        # inception module\n",
        "        self.inp1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(1,1), padding='same'),\n",
        "            nn.LeakyReLU(negative_slope=0.01),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3,1), padding='same'),\n",
        "            nn.LeakyReLU(negative_slope=0.01),\n",
        "            nn.BatchNorm2d(64),\n",
        "        )\n",
        "        self.inp2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(1,1), padding='same'),\n",
        "            nn.LeakyReLU(negative_slope=0.01),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(5,1), padding='same'),\n",
        "            nn.LeakyReLU(negative_slope=0.01),\n",
        "            nn.BatchNorm2d(64),\n",
        "        )\n",
        "        self.inp3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(1,1), padding='same'),\n",
        "            nn.LeakyReLU(negative_slope=0.01),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(7,1), padding='same'),\n",
        "            nn.LeakyReLU(negative_slope=0.01),\n",
        "            nn.BatchNorm2d(64),\n",
        "        )\n",
        "        self.inp4 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(1,1), padding='same'),\n",
        "            nn.LeakyReLU(negative_slope=0.01),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(9,1), padding='same'),\n",
        "            nn.LeakyReLU(negative_slope=0.01),\n",
        "            nn.BatchNorm2d(64),\n",
        "        )\n",
        "        self.inp5 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(1,1), padding='same'),\n",
        "            nn.LeakyReLU(negative_slope=0.01),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(11,1), padding='same'),\n",
        "            nn.LeakyReLU(negative_slope=0.01),\n",
        "            nn.BatchNorm2d(64),\n",
        "        )\n",
        "        \n",
        "        # lstm layers\n",
        "        self.lstm = nn.LSTM(input_size=320, hidden_size=64, num_layers=1, batch_first=True)\n",
        "        self.fc1 = nn.Linear(64, 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # h0: (number of hidden layers, batch size, hidden size)\n",
        "        h0 = torch.zeros(1, x.size(0), 64).to(device)\n",
        "        c0 = torch.zeros(1, x.size(0), 64).to(device)\n",
        "        #print(x.shape)\n",
        "        x = self.conv1(x)\n",
        "        #print(x.shape)\n",
        "        x = self.conv2(x)\n",
        "        #print(x.shape)\n",
        "        x = self.conv3(x)\n",
        "        #print(x.shape)\n",
        "        x_inp1 = self.inp1(x)\n",
        "        x_inp2 = self.inp2(x)\n",
        "        x_inp3 = self.inp3(x) \n",
        "        x_inp4 = self.inp4(x)\n",
        "        x_inp5 = self.inp5(x)\n",
        "        x = torch.cat((x_inp1, x_inp2, x_inp3, x_inp4, x_inp5), dim=1)\n",
        "        #print(x.shape)\n",
        "        \n",
        "        x = x.permute(0, 2, 1, 3)\n",
        "        #print(x.shape)\n",
        "        x = torch.reshape(x, (-1, x.shape[1], x.shape[2]))\n",
        "        \n",
        "        x, _ = self.lstm(x, (h0, c0))\n",
        "        x = x[:, -1, :]\n",
        "        x = self.fc1(x)\n",
        "        forecast_y = torch.softmax(x, dim=1)\n",
        "        \n",
        "        return forecast_y"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model Training**"
      ],
      "metadata": {
        "id": "bejZgDmCkkHi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "s_u5esKfTT-S"
      },
      "outputs": [],
      "source": [
        "model = deeplob()\n",
        "model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001)\n",
        "#optimizer = torch.optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)\n",
        "def batch_gd(model, criterion, optimizer, train_loader, test_loader, epochs):\n",
        "    \n",
        "    train_losses = np.zeros(epochs)\n",
        "    test_losses = np.zeros(epochs)\n",
        "    best_test_loss = np.inf\n",
        "    best_test_epoch = 0\n",
        "\n",
        "    for it in tqdm(range(epochs)):\n",
        "        \n",
        "        model.train()\n",
        "        t0 = datetime.now()\n",
        "        train_loss = []\n",
        "        for inputs, targets in train_loader:\n",
        "            # move data to GPU\n",
        "            inputs, targets = inputs.to(device, dtype=torch.float), targets.to(device, dtype=torch.int64)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            # Backward and optimize\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss.append(loss.item())\n",
        "        # Get train loss and test loss\n",
        "        train_loss = np.mean(train_loss)\n",
        "    \n",
        "        model.eval()\n",
        "        test_loss = []\n",
        "        for inputs, targets in test_loader:\n",
        "            inputs, targets = inputs.to(device, dtype=torch.float), targets.to(device, dtype=torch.int64)      \n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            test_loss.append(loss.item())\n",
        "        test_loss = np.mean(test_loss)\n",
        "\n",
        "        # Save losses\n",
        "        train_losses[it] = train_loss\n",
        "        test_losses[it] = test_loss\n",
        "        \n",
        "        #We save the best model\n",
        "        if test_loss < best_test_loss:\n",
        "            torch.save(model, '/content/drive/MyDrive/Output/best_model_DeepLOB')\n",
        "            best_test_loss = test_loss\n",
        "            best_test_epoch = it\n",
        "            print('model saved')\n",
        "\n",
        "        dt = datetime.now() - t0\n",
        "        print(f'Epoch {it+1}/{epochs}, Train Loss: {train_loss:.4f}, \\\n",
        "          Validation Loss: {test_loss:.4f}, Duration: {dt}, Best Val Epoch: {best_test_epoch}')\n",
        "\n",
        "    return train_losses, test_losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9vq-ZAzTb6K",
        "outputId": "59051522-dd70-4dcf-c55f-c5541006611a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|â–         | 1/50 [09:52<8:03:58, 592.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model saved\n",
            "Epoch 1/50, Train Loss: 0.8488,           Validation Loss: 0.7479, Duration: 0:09:52.620635, Best Val Epoch: 0\n"
          ]
        }
      ],
      "source": [
        "train_losses, val_losses = batch_gd(model, criterion, optimizer, \n",
        "                                    train_loader, val_loader, epochs=50)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(15,6))\n",
        "plt.plot(train_losses, label='train loss')\n",
        "plt.plot(val_losses, label='validation loss')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model Testing**"
      ],
      "metadata": {
        "id": "F7CF2CwUkn4G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TFg5d6CzTgWS"
      },
      "outputs": [],
      "source": [
        "model = torch.load('/content/drive/MyDrive/Output/best_model_DeepLOB')\n",
        "\n",
        "n_correct = 0.\n",
        "n_total = 0.\n",
        "for inputs, targets in test_loader:\n",
        "    # Move to GPU\n",
        "    inputs, targets = inputs.to(device, dtype=torch.float), targets.to(device, dtype=torch.int64)\n",
        "\n",
        "    # Forward pass\n",
        "    outputs = model(inputs)\n",
        "    \n",
        "    # Get prediction\n",
        "    # torch.max returns both max and argmax\n",
        "    _, predictions = torch.max(outputs, 1)\n",
        "\n",
        "    # update counts\n",
        "    n_correct += (predictions == targets).sum().item()\n",
        "    n_total += targets.shape[0]\n",
        "\n",
        "test_acc = n_correct / n_total\n",
        "print(f\"Test acc: {test_acc:.4f}\")\n",
        "\n",
        "all_targets = []\n",
        "all_predictions = []\n",
        "\n",
        "for inputs, targets in test_loader:\n",
        "    # Move to GPU\n",
        "    inputs, targets = inputs.to(device, dtype=torch.float), targets.to(device, dtype=torch.int64)\n",
        "\n",
        "    # Forward pass\n",
        "    outputs = model(inputs)\n",
        "    \n",
        "    # Get prediction\n",
        "    # torch.max returns both max and argmax\n",
        "    _, predictions = torch.max(outputs, 1)\n",
        "\n",
        "    all_targets.append(targets.cpu().numpy())\n",
        "    all_predictions.append(predictions.cpu().numpy())\n",
        "\n",
        "all_targets = np.concatenate(all_targets)    \n",
        "all_predictions = np.concatenate(all_predictions)    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0oOu5lwf6zw0"
      },
      "outputs": [],
      "source": [
        "print('accuracy_score:', accuracy_score(all_targets, all_predictions))\n",
        "print(classification_report(all_targets, all_predictions, digits=4))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
