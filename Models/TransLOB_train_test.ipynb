{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# load packages\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from google.colab import drive\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from torch.utils import data\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from keras import layers\n",
        "from keras.layers import Conv1D, BatchNormalization\n",
        "import tensorflow as tf\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6v9OTvU2i-X",
        "outputId": "7c093712-c849-4222-8377-61cb83dba23e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "dec_data = np.loadtxt('/content/drive/MyDrive/Data/Train_Dst_NoAuction_ZScore_CF_7.txt')\n",
        "dec_train = dec_data[:, :int(dec_data.shape[1] * 0.8)]\n",
        "dec_val = dec_data[:, int(dec_data.shape[1] * 0.8):]\n",
        "\n",
        "dec_test1 = np.loadtxt('/content/drive/MyDrive/Data/Test_Dst_NoAuction_ZScore_CF_7.txt')\n",
        "dec_test2 = np.loadtxt('/content/drive/MyDrive/Data/Test_Dst_NoAuction_ZScore_CF_8.txt')\n",
        "dec_test3 = np.loadtxt('/content/drive/MyDrive/Data/Test_Dst_NoAuction_ZScore_CF_9.txt')\n",
        "dec_test = np.hstack((dec_test1, dec_test2, dec_test3))\n",
        "\n",
        "print(dec_train.shape, dec_val.shape, dec_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLqRMXQF2sa8",
        "outputId": "d3c39b3e-5d54-4dc4-dd99-5fea89f772eb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(149, 203800) (149, 50950) (149, 139587)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_x(data):\n",
        "    df1 = data[:40, :].T\n",
        "    return np.array(df1)\n",
        "\n",
        "def get_label(data):\n",
        "    lob = data[-5:, :].T\n",
        "    return lob\n",
        "\n",
        "def data_classification(X, Y, T):\n",
        "    [N, D] = X.shape\n",
        "    df = np.array(X)\n",
        "\n",
        "    dY = np.array(Y)\n",
        "\n",
        "    dataY = dY[T - 1:N]\n",
        "\n",
        "    dataX = np.zeros((N - T + 1, T, D))\n",
        "    for i in range(T, N + 1):\n",
        "        dataX[i - T] = df[i - T:i, :]\n",
        "\n",
        "    return dataX, dataY\n",
        "\n",
        "def torch_data(x, y):\n",
        "    x = torch.from_numpy(x)\n",
        "    x = torch.unsqueeze(x, 1)\n",
        "    y = torch.from_numpy(y)\n",
        "    y = F.one_hot(y, num_classes=3)\n",
        "    return x, y"
      ],
      "metadata": {
        "id": "yNcpcZkK3iab"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset(data.Dataset):\n",
        "    \"\"\"Characterizes a dataset for PyTorch\"\"\"\n",
        "    def __init__(self, data, k, num_classes, T):\n",
        "        \"\"\"Initialization\"\"\" \n",
        "        self.k = k\n",
        "        self.num_classes = num_classes\n",
        "        self.T = T\n",
        "            \n",
        "        x = prepare_x(data)\n",
        "        y = get_label(data)\n",
        "        x, y = data_classification(x, y, self.T)\n",
        "        y = y[:,self.k] - 1\n",
        "        self.length = len(x)\n",
        "\n",
        "        x = torch.from_numpy(x)\n",
        "        self.x = torch.unsqueeze(x, 1)\n",
        "        self.y = torch.from_numpy(y)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Denotes the total number of samples\"\"\"\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"Generates samples of data\"\"\"\n",
        "        return self.x[index], self.y[index]\n"
      ],
      "metadata": {
        "id": "yU-3oai73Sof"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "\n",
        "dataset_train = Dataset(data=dec_train, k=4, num_classes=3, T=100)\n",
        "dataset_val = Dataset(data=dec_val, k=4, num_classes=3, T=100)\n",
        "dataset_test = Dataset(data=dec_test, k=4, num_classes=3, T=100)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=dataset_train, batch_size=batch_size, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(dataset=dataset_val, batch_size=batch_size, shuffle=False)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=dataset_test, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(dataset_train.x.shape, dataset_train.y.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hX50EjbR2xJh",
        "outputId": "60d15404-db09-435f-b9eb-abcfda7a45ca"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([203701, 1, 100, 40]) torch.Size([203701])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from copy import deepcopy\n",
        "from typing import List\n",
        "from typing import Tuple\n",
        "from typing import Union\n",
        "\n",
        "from torch import Tensor\n",
        "from torch.nn import Conv1d\n",
        "from torch.nn import Module\n",
        "from torch.nn import ReLU\n",
        "from torch.nn import ReplicationPad1d\n",
        "from torch.nn import Sequential\n",
        "from torch.nn import ConstantPad1d\n",
        "\n",
        "class CausalConv1d(Sequential):\n",
        "    r\"\"\"Applies a 1D convolution with causal padding.\n",
        "    Args:\n",
        "        in_channels (int): Number of channels in the input sequence.\n",
        "        out_channels (int): Number of channels produced by the convolution.\n",
        "        kernel_size (int): Size of the convolving kernel.\n",
        "        dilation (int, default=1): Spacing between kernel elements.\n",
        "    Shape:\n",
        "        - Input: :math:`(N, C_{\\text{in}}, L)`\n",
        "        - Output: :math:`(N, C_{\\text{out}}, L)` where :math:`N` is the batch size,\n",
        "          :math:`C_{\\text{in}}` is the number of channels in the input sequence,\n",
        "          :math:`C_{\\text{out}}` is the number of channels in the output sequence,\n",
        "          :math:`L` is the length of the sequence.\n",
        "    Examples:\n",
        "        >>> import torch\n",
        "        >>>\n",
        "        >>> m = CausalConv1d(40, 14, 2, dilation=1)\n",
        "        >>> m\n",
        "        CausalConv1d(40, 14, kernel_size=(2,), stride=(1,))\n",
        "        >>>\n",
        "        >>> input = torch.empty(1, 40, 100)\n",
        "        >>> m(input).size()\n",
        "        torch.Size([1, 14, 100])\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self, in_channels: int, out_channels: int, kernel_size: int, dilation: int = 1\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.pad = ReplicationPad1d(((kernel_size - 1) * dilation, 0))\n",
        "        self.conv = Conv1d(in_channels, out_channels, kernel_size, dilation=dilation)\n",
        "\n",
        "    def forward(self, input: Tensor) -> Tensor:\n",
        "        #print(input.shape)\n",
        "        return self.conv(self.pad(input))\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return self._get_name() + f\"({self.conv.extra_repr()})\"\n",
        "\n",
        "\n",
        "class CausalConvLayers(Sequential):\n",
        "    r\"\"\"Applies dilated causal convolution.\n",
        "    Args:\n",
        "        in_features (int): The number of channels in the input sequence.\n",
        "        channels (int): The number of channels in the intermediate and output sequences.\n",
        "        kernel_size (int): Size of the convolving kernel.\n",
        "        dilation (int or tuple[int], default=1):\n",
        "            If int, use the common value of dilation for each layer.\n",
        "            If tuple[int], use different value for each layer.\n",
        "        n_layers (int, default=5): The number of causal convolutional layer in the module.\n",
        "    Shapes:\n",
        "        - Input: :math:`(N, C_{\\text{in}}, L)`\n",
        "        - Output: :math:`(N, C_{\\text{out}}, L)` where :math:`N` is the batch size,\n",
        "          :math:`C_{\\text{in}}` is the number of channels in the input sequence,\n",
        "          :math:`C_{\\text{out}}` is the number of channels in the output sequence,\n",
        "          :math:`L` is the length of the sequence.\n",
        "    Examples:\n",
        "        >>> import torch\n",
        "        >>>\n",
        "        >>> _ = torch.manual_seed(42)\n",
        "        >>> m = CausalConvLayers(40, 14, 2, dilation=(1, 2, 4, 8, 16))\n",
        "        >>> m\n",
        "        CausalConvLayers(\n",
        "          (0): CausalConv1d(40, 14, kernel_size=(2,), stride=(1,))\n",
        "          (1): ReLU()\n",
        "          (2): CausalConv1d(14, 14, kernel_size=(2,), stride=(1,), dilation=(2,))\n",
        "          (3): ReLU()\n",
        "          (4): CausalConv1d(14, 14, kernel_size=(2,), stride=(1,), dilation=(4,))\n",
        "          (5): ReLU()\n",
        "          (6): CausalConv1d(14, 14, kernel_size=(2,), stride=(1,), dilation=(8,))\n",
        "          (7): ReLU()\n",
        "          (8): CausalConv1d(14, 14, kernel_size=(2,), stride=(1,), dilation=(16,))\n",
        "        )\n",
        "        >>> input = torch.empty((1, 40, 100))\n",
        "        >>> m(input).size()\n",
        "        torch.Size([1, 14, 100])\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels: int,\n",
        "        n_features: int,\n",
        "        kernel_size: int,\n",
        "        dilation: Union[Tuple[int, ...], int] = 1,\n",
        "        n_layers: int = 5,\n",
        "        activation: Module = ReLU(),\n",
        "    ):\n",
        "        if isinstance(dilation, int):\n",
        "            dilation = (dilation,) * n_layers\n",
        "\n",
        "        layers: List[Module] = []\n",
        "        for i in range(n_layers):\n",
        "            c = in_channels if i == 0 else n_features\n",
        "            layers.append(CausalConv1d(c, n_features, kernel_size, dilation[i]))\n",
        "            if i != n_layers - 1:\n",
        "                layers.append(deepcopy(activation))\n",
        "        print(layers)\n",
        "        super().__init__(*layers)"
      ],
      "metadata": {
        "id": "uiUWlpq14ali"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from copy import deepcopy\n",
        "from typing import List\n",
        "\n",
        "from torch.nn import Linear\n",
        "from torch.nn import Module\n",
        "from torch.nn import ReLU\n",
        "from torch.nn import Sequential\n",
        "\n",
        "\n",
        "class MultiLayerPerceptron(Sequential):\n",
        "    \"\"\"Multi-layer perceptron.\n",
        "    Args:\n",
        "        in_features (int): size of each input sample.\n",
        "        out_features (int): size of each output sample.\n",
        "        n_layers (int): number of hidden layers.\n",
        "        n_units (int): number of units in each hidden layer.\n",
        "        activation (Module): activation module in hidden layers.\n",
        "    Shape:\n",
        "        - Input: :math:`(N, *, H_in)` where\n",
        "          :math:`*` means any number of additional dimensions and\n",
        "          :math`H_in` is ``in_features``.\n",
        "        - Output: :math:`(N, *, H_out)` where\n",
        "          all but the last dimension are the same shape as the input and\n",
        "          :math:`H_out` is ``out_features``.\n",
        "    Examples:\n",
        "        >>> import torch\n",
        "        >>>\n",
        "        >>> m = MultiLayerPerceptron(2, 3)\n",
        "        >>> m\n",
        "        MultiLayerPerceptron(\n",
        "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
        "          (1): ReLU()\n",
        "          (2): Linear(in_features=32, out_features=32, bias=True)\n",
        "          (3): ReLU()\n",
        "          (4): Linear(in_features=32, out_features=3, bias=True)\n",
        "        )\n",
        "        >>> m(torch.empty(1, 2)).size()\n",
        "        torch.Size([1, 3])\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_features: int,\n",
        "        out_features: int,\n",
        "        n_layers: int = 2,\n",
        "        n_units: int = 32,\n",
        "        activation: Module = ReLU(),\n",
        "    ) -> None:\n",
        "        layers: List[Module] = []\n",
        "        for i_layer in range(n_layers):\n",
        "            layers.append(Linear(in_features if i_layer == 0 else n_units, n_units))\n",
        "            layers.append(deepcopy(activation))\n",
        "        layers.append(Linear(n_units, out_features))\n",
        "\n",
        "        super().__init__(*layers)"
      ],
      "metadata": {
        "id": "7qrTGKej4pwy"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "import torch\n",
        "from torch import Tensor\n",
        "from torch.nn import Module\n",
        "\n",
        "\n",
        "class PositionalEncoding(Module):\n",
        "    \"\"\"Positional encoder.\n",
        "    Args:\n",
        "        d_model (int, default=1): Dimension of the model.\n",
        "        max_length (int, default=100): Maximum length of the sequence\n",
        "        encoding ({\"linear\"}): Method of encoding.\n",
        "            For \"linear\":\n",
        "                y = x / max_length\n",
        "                x : position in the sequence\n",
        "                y : positional encoder\n",
        "    Shape:\n",
        "        - Input: :math:`(N, *, X, L)` where :math:`N` is the batch size,\n",
        "          :math:`X` is the number of features in the input,\n",
        "          :math:`F` is the number of features in the positional encoding,\n",
        "          :math:`L` is the length of the sequence,\n",
        "          :math:`*` is any number of additional dimensions.\n",
        "        - Output: :math:`(N, *, X + F, L)`.\n",
        "    Examples:\n",
        "        >>> _ = torch.manual_seed(42)\n",
        "        >>> x = torch.randn(1, 2, 10)\n",
        "        >>> m = PositionalEncoding()\n",
        "        >>> m(x).size()\n",
        "        torch.Size([1, 3, 10])\n",
        "    \"\"\"\n",
        "\n",
        "    positional_encoder: Tensor\n",
        "\n",
        "    def __init__(\n",
        "        self, d_model: int = 1, max_length: int = 100, encoding: str = \"linear\"\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.max_length = max_length\n",
        "        self.encoding = encoding\n",
        "\n",
        "        self.register_buffer(\"positional_encoder\", self._compute_positional_encoder())\n",
        "\n",
        "    def _compute_positional_encoder(self) -> Tensor:\n",
        "        # Returns:\n",
        "        # positional_encoder : tensor, shape (F, L)\n",
        "        #     F : number of features\n",
        "        #     L : maximum length\n",
        "        if self.encoding == \"sinusoid\":\n",
        "            position = torch.linspace(0.0, 2 * math.pi, self.max_length).reshape(-1, 1)\n",
        "            frequency = torch.logspace(0.0, math.log(2 * math.pi), self.d_model, math.e)\n",
        "            frequency = frequency.unsqueeze(0)\n",
        "\n",
        "            phase = frequency * position\n",
        "\n",
        "            positional_encoder = torch.empty((self.max_length, 2 * self.d_model))\n",
        "            positional_encoder[:, 0::2] = phase.sin()\n",
        "            positional_encoder[:, 1::2] = phase.cos()\n",
        "\n",
        "        if self.encoding == \"linear\":\n",
        "            positional_encoder = torch.linspace(0.0, 1.0, self.max_length).unsqueeze(0)\n",
        "        else:\n",
        "            raise ValueError(\"invalid 'encoding'\")\n",
        "\n",
        "        return positional_encoder\n",
        "\n",
        "    def forward(self, input: Tensor) -> Tensor:\n",
        "        # cut and align shape\n",
        "        p = self.positional_encoder[..., : input.size(-1)]\n",
        "        # for input shape (N, *, X, L), p's shape is (N, *, F, L)\n",
        "        p = p.expand(input.size()[:-2] + p.size()[-2:])\n",
        "        return torch.cat((input, p), -2)"
      ],
      "metadata": {
        "id": "2pBEm8K84xCK"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import Tensor\n",
        "from torch.nn import TransformerEncoderLayer\n",
        "\n",
        "\n",
        "class CausalTransformerEncoderLayer(TransformerEncoderLayer):\n",
        "    \"\"\"Transformer encoder layer with causal mask.\n",
        "    See :class:`torch.nn.TransformerEncoderLayer` for details.\n",
        "    Examples:\n",
        "        >>> L, N, E = 5, 1, 2  # sequence length, batch, features\n",
        "        >>> m = CausalTransformerEncoderLayer(E, 1)\n",
        "        >>> src = torch.empty(L, N, E)\n",
        "        >>> m.causal_mask(src)\n",
        "        tensor([[False,  True,  True,  True,  True],\n",
        "                [False, False,  True,  True,  True],\n",
        "                [False, False, False,  True,  True],\n",
        "                [False, False, False, False,  True],\n",
        "                [False, False, False, False, False]])\n",
        "        >>> assert m(src).size() == src.size()\n",
        "    \"\"\"\n",
        "\n",
        "    def causal_mask(self, src: Tensor) -> Tensor:\n",
        "        # In PyTorch documentation of MultiHeadAttention:\n",
        "        # > (L, S) where L is the target sequence length,\n",
        "        # > S is the source sequence length.\n",
        "        query, key, value = src, src, src\n",
        "        trues = torch.ones(\n",
        "            (query.size(0), key.size(0)), dtype=torch.bool, device=src.device\n",
        "        )\n",
        "        return trues.triu(diagonal=1)\n",
        "\n",
        "    def forward(self, src: Tensor, *args, **kwargs) -> Tensor:\n",
        "        return super().forward(src, src_mask=self.causal_mask(src))"
      ],
      "metadata": {
        "id": "u2WrotiB41Ya"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "oM6BhCu-2emi"
      },
      "outputs": [],
      "source": [
        "from typing import Tuple\n",
        "from typing import Union\n",
        "\n",
        "import torch\n",
        "from torch import Tensor\n",
        "from torch.nn import Dropout\n",
        "from torch.nn import Flatten\n",
        "from torch.nn import LayerNorm\n",
        "from torch.nn import Linear\n",
        "from torch.nn import Module\n",
        "from torch.nn import Sequential\n",
        "from torch.nn import Softmax\n",
        "from torch.nn import TransformerEncoder\n",
        "\n",
        "#from .conv import CausalConvLayers\n",
        "#from .mlp import MultiLayerPerceptron\n",
        "#from .position import PositionalEncoding\n",
        "#from .transformer import CausalTransformerEncoderLayer\n",
        "\n",
        "\n",
        "class TransLOB(Module):\n",
        "    r\"\"\"Transformers for limit order books.\n",
        "    Default values are the same with the original paper, unless stated otherwise.\n",
        "    Reference:\n",
        "        - Transformers for limit order books, James Wallbridge (2020)\n",
        "          https://github.com/jwallbridge/translob\n",
        "    Args:\n",
        "        in_features (int, default=40): The number of input features.\n",
        "        out_features (int, default=3): The number of output features.\n",
        "        out_activation (torch.nn.Module, default=torch.nn.Softmax(-1)):\n",
        "            The activation layer applied to the output.\n",
        "        conv_n_layers (int, default=5): The number of convolutional layers.\n",
        "        conv_n_features (int, default=14): The number of features\n",
        "            in the convolutional layers.\n",
        "        conv_kernel_size (int, default=2): The kernel size\n",
        "            in the convolutional layers.\n",
        "        conv_dilation (int or tuple[int], default=(1, 2, 4, 8, 16)): The dilation(s)\n",
        "            in the convolutional layers.\n",
        "        tf_n_channels: (int, default=3): The number of channels\n",
        "            in the multi-head self-attension of Transformer encoder.\n",
        "            Its default value may be different from the original implementation.\n",
        "            Its default value (denoted \"C\" in the paper?) does not seem to be\n",
        "            clarified in the original papar and so we set the default value arbitrarily.\n",
        "        tf_dim_feedforward (int, default=60): The dimension of feed-forward\n",
        "            network model in Transformer encoder.\n",
        "        tf_dropout_rate (float, default=0.0): Dropout rate in Transformer encoder.\n",
        "        tf_num_layers (int, default=2): Number of sub-encoder-layers in the Transformer encoder.\n",
        "        mlp_dim (int, default=64):\n",
        "            Dimension of feedforward network model after Transformer encoder.\n",
        "        mlp_n_layers (int, default=1):\n",
        "            Number of layers in feedforward network model after Transformer encoder.\n",
        "        dropout_rate (float, default=0.1):\n",
        "            Dropout rate after Transformer encoder.\n",
        "    Shapes:\n",
        "        - Input: :math:`(N, C, L)` where :math:`N` is the batch size,\n",
        "          :math:`C` is the number of features and\n",
        "          :math:`L` is the length of the sequence.\n",
        "          :math:`C = 40` in the original paper: ask/bid, level 1-10, and price/volume.\n",
        "          :math:`L = 100` in the original paper.\n",
        "        - Output: :math:`(N, N_{\\text{out}})`\n",
        "          :math:`N_{\\text{out}} = 3` in the original paper (up, down, and neutral).\n",
        "    Examples:\n",
        "        >>> import torch\n",
        "        >>>\n",
        "        >>> m = TransLOB()\n",
        "        >>> input = torch.empty(1, 40, 100)\n",
        "        >>> m(input).size()\n",
        "        torch.Size([1, 3])\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_features: int = 40,\n",
        "        out_features: int = 3,\n",
        "        len_sequence: int = 100,\n",
        "        out_activation: Module = Softmax(-1),\n",
        "        conv_n_features: int = 14,\n",
        "        conv_kernel_size: int = 2,\n",
        "        conv_dilation: Union[Tuple[int, ...], int] = (1, 2, 4, 8, 16),\n",
        "        conv_n_layers: int = 5,\n",
        "        tf_n_channels: int = 3,\n",
        "        tf_dim_feedforward: int = 60,\n",
        "        tf_dropout_rate: float = 0.0,\n",
        "        tf_num_layers: int = 2,\n",
        "        mlp_dim: int = 64,\n",
        "        mlp_n_layers: int = 1,\n",
        "        dropout_rate: float = 0.1,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        # Define convolutional module.\n",
        "        convolution = CausalConvLayers(\n",
        "            in_features,\n",
        "            conv_n_features,\n",
        "            conv_kernel_size,\n",
        "            dilation=conv_dilation,\n",
        "            n_layers=conv_n_layers,\n",
        "        )\n",
        "        self.pre_transformer = Sequential(\n",
        "            convolution,\n",
        "            LayerNorm(torch.Size((conv_n_features, len_sequence))),\n",
        "            PositionalEncoding(max_length=len_sequence),\n",
        "        )\n",
        "\n",
        "        # Define Transformer encoder module.\n",
        "        d_model = conv_n_features + 1\n",
        "        encoder_layer = CausalTransformerEncoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=tf_n_channels,\n",
        "            dim_feedforward=tf_dim_feedforward,\n",
        "            dropout=tf_dropout_rate,\n",
        "        )\n",
        "        self.transformer = TransformerEncoder(encoder_layer, num_layers=tf_num_layers)\n",
        "\n",
        "        # Define modules used after Transformer encoder.\n",
        "        multi_layer_perceptron = MultiLayerPerceptron(\n",
        "            in_features=d_model * len_sequence,\n",
        "            out_features=mlp_dim,\n",
        "            n_layers=mlp_n_layers,\n",
        "            n_units=mlp_dim,\n",
        "        )\n",
        "        self.post_transformer = Sequential(\n",
        "            Flatten(1, -1),\n",
        "            multi_layer_perceptron,\n",
        "            Dropout(dropout_rate),\n",
        "            Linear(mlp_dim, out_features),\n",
        "            out_activation,\n",
        "        )\n",
        "\n",
        "    def forward(self, input: Tensor) -> Tensor:\n",
        "        input = self.pre_transformer(input).movedim(-1, 0)\n",
        "        input = self.transformer(input)\n",
        "        input = self.post_transformer(input.movedim(0, -1))\n",
        "        return input\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = TransLOB(in_features= 40,\n",
        "        out_features = 3,\n",
        "        len_sequence = 100,\n",
        "        out_activation= Softmax(-1),\n",
        "        conv_n_features = 14,\n",
        "        conv_kernel_size = 2,\n",
        "        conv_dilation = (1, 2, 4, 8, 16),\n",
        "        conv_n_layers = 5,\n",
        "        tf_n_channels = 3,\n",
        "        tf_dim_feedforward = 60,\n",
        "        tf_dropout_rate = 0.0,\n",
        "        tf_num_layers = 2,\n",
        "        mlp_dim = 64,\n",
        "        mlp_n_layers = 1,\n",
        "        dropout_rate = 0.1).to(device)\n",
        "input = torch.empty(1, 40, 100)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCfn808x25lq",
        "outputId": "9579370c-c4db-4581-9c21-0eb8024460d1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CausalConv1d(40, 14, kernel_size=(2,), stride=(1,)), ReLU(), CausalConv1d(14, 14, kernel_size=(2,), stride=(1,), dilation=(2,)), ReLU(), CausalConv1d(14, 14, kernel_size=(2,), stride=(1,), dilation=(4,)), ReLU(), CausalConv1d(14, 14, kernel_size=(2,), stride=(1,), dilation=(8,)), ReLU(), CausalConv1d(14, 14, kernel_size=(2,), stride=(1,), dilation=(16,))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "w8sftV1yH4Ln"
      },
      "outputs": [],
      "source": [
        "# A function to encapsulate the training loop\n",
        "def batch_gd(model, criterion, optimizer, train_loader, test_loader, epochs):\n",
        "    \n",
        "    train_losses = np.zeros(epochs)\n",
        "    test_losses = np.zeros(epochs)\n",
        "    best_test_loss = np.inf\n",
        "    best_test_epoch = 0\n",
        "\n",
        "    for it in tqdm(range(epochs)):\n",
        "        \n",
        "        model.train()\n",
        "        t0 = datetime.now()\n",
        "        train_loss = []\n",
        "        for inputs, targets in train_loader:\n",
        "            # move data to GPU\n",
        "            inputs, targets = inputs.to(device, dtype=torch.float), targets.to(device, dtype=torch.int64)\n",
        "            # print(\"inputs.shape:\", inputs.shape)\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "            inputs = torch.squeeze(inputs, 1)\n",
        "            inputs = torch.permute(inputs, (0, 2, 1))\n",
        "            # Forward pass\n",
        "            # print(\"about to get model output\")\n",
        "            #print(inputs.shape)\n",
        "            outputs = model(inputs)\n",
        "            # print(\"done getting model output\")\n",
        "            # print(\"outputs.shape:\", outputs.shape, \"targets.shape:\", targets.shape)\n",
        "            loss = criterion(outputs, targets)\n",
        "            # Backward and optimize\n",
        "            # print(\"about to optimize\")\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss.append(loss.item())\n",
        "        # Get train loss and test loss\n",
        "        train_loss = np.mean(train_loss) # a little misleading\n",
        "    \n",
        "        model.eval()\n",
        "        test_loss = []\n",
        "        for inputs, targets in test_loader:\n",
        "            inputs, targets = inputs.to(device, dtype=torch.float), targets.to(device, dtype=torch.int64)      \n",
        "            inputs = torch.squeeze(inputs, 1)\n",
        "            inputs = torch.permute(inputs, (0, 2, 1))\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            test_loss.append(loss.item())\n",
        "        test_loss = np.mean(test_loss)\n",
        "\n",
        "        # Save losses\n",
        "        train_losses[it] = train_loss\n",
        "        test_losses[it] = test_loss\n",
        "        \n",
        "        if test_loss < best_test_loss:\n",
        "            torch.save(model, './best_val_model_pytorch')\n",
        "            best_test_loss = test_loss\n",
        "            best_test_epoch = it\n",
        "            print('model saved')\n",
        "\n",
        "        dt = datetime.now() - t0\n",
        "        print(f'Epoch {it+1}/{epochs}, Train Loss: {train_loss:.4f}, \\\n",
        "          Validation Loss: {test_loss:.4f}, Duration: {dt}, Best Val Epoch: {best_test_epoch}')\n",
        "\n",
        "    return train_losses, test_losses"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses, val_losses = batch_gd(model, criterion, optimizer, \n",
        "                                    train_loader, val_loader, epochs=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvr2CzE03DGk",
        "outputId": "9aa780a6-6f84-4aef-c181-43947b834030"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 1/50 [01:21<1:06:47, 81.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model saved\n",
            "Epoch 1/50, Train Loss: 1.0184,           Validation Loss: 1.0686, Duration: 0:01:21.778518, Best Val Epoch: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 2/50 [02:36<1:02:19, 77.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/50, Train Loss: 0.9746,           Validation Loss: 1.0691, Duration: 0:01:15.183190, Best Val Epoch: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 3/50 [03:53<1:00:23, 77.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model saved\n",
            "Epoch 3/50, Train Loss: 0.9574,           Validation Loss: 1.0632, Duration: 0:01:16.133175, Best Val Epoch: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 4/50 [05:07<58:25, 76.20s/it]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/50, Train Loss: 0.9420,           Validation Loss: 1.0638, Duration: 0:01:14.825116, Best Val Epoch: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load('/content/drive/MyDrive/Output/best_model_CNN_FI')\n",
        "\n",
        "n_correct = 0.\n",
        "n_total = 0.\n",
        "all_targets = []\n",
        "all_predictions = []\n",
        "\n",
        "for inputs, targets in test_loader:\n",
        "    # Move to GPU\n",
        "    inputs, targets = inputs.to(device, dtype=torch.float), targets.to(device, dtype=torch.int64)\n",
        "\n",
        "    # Forward pass\n",
        "    outputs = model(inputs)\n",
        "    \n",
        "    # Get prediction\n",
        "    # torch.max returns both max and argmax\n",
        "    _, predictions = torch.max(outputs, 1)\n",
        "\n",
        "    # update counts\n",
        "    n_correct += (predictions == targets).sum().item()\n",
        "    n_total += targets.shape[0]\n",
        "\n",
        "    all_targets.append(targets.cpu().numpy())\n",
        "    all_predictions.append(predictions.cpu().numpy())\n",
        "\n",
        "test_acc = n_correct / n_total\n",
        "print(f\"Test acc: {test_acc:.4f}\")\n",
        "  \n",
        "all_targets = np.concatenate(all_targets)    \n",
        "all_predictions = np.concatenate(all_predictions)  "
      ],
      "metadata": {
        "id": "9zo9qZRFPZ2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('accuracy_score:', accuracy_score(all_targets, all_predictions))\n",
        "print(classification_report(all_targets, all_predictions, digits=4))\n",
        "\n",
        "c = confusion_matrix(all_targets, all_predictions, normalize=\"true\")\n",
        "disp = ConfusionMatrixDisplay(c)\n",
        "disp.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hrt7Bd2lPUOt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}